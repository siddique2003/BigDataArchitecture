spark.hadoop.fs.defaultFS=hdfs://172.18.0.4:9000
spark.hadoop.fs.hdfs.impl=org.apache.hadoop.hdfs.DistributedFileSystem
spark.hadoop.fs.file.impl=org.apache.hadoop.fs.LocalFileSystem
spark.hadoop.dfs.client.use.datanode.hostname=true
spark.master spark://172.18.0.8:7077
spark.jars /opt/spark/jars/spark/hbase-spark-1.0.1.jar,/opt/spark/jars/spark/hbase-client-2.1.3.jar,/opt/spark/jars/spark/hbase-common-2.1.3.jar,/opt/spark/jars/spark/hbase-server-2.1.3.jar,/opt/spark/jars/spark/hbase-mapreduce-2.1.3.jar


spark.default.parallelism=500
spark.sql.shuffle.partitions=500

spark.executor.memory=2g
spark.driver.memory=1g

spark.eventLog.enabled=true
spark.eventLog.dir=file:///tmp/spark-events

spark.dynamicAllocation.enabled=true
spark.dynamicAllocation.initialExecutors=2
spark.dynamicAllocation.minExecutors=1
spark.dynamicAllocation.maxExecutors=10

spark.hadoop.io.compression.codecs=org.apache.hadoop.io.compress.GzipCodec,org.apache.hadoop.io.compress.DefaultCodec,org.apache.hadoop.io.compress.SnappyCodec

spark.checkpoint.dir=hdfs://172.18.0.4:9000/spark-checkpoints
